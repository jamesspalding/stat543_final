---
title: "Predicting Poverty"
author: "James Spalding, Ben Bronoski, Matt Nowell, Yaya Barrow"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, include = F, message = F)

library(tidyverse)
library(VGAM)
library(nnet)
library(pROC)
library(caret)
library(glmnet)
library(gt)
library(gtExtras)

select = dplyr::select
```
# Introduction

There is a constant struggle to ensure people are being given access to the correct amount of aid they need to survive. Some programs target some of the poorest populations to ensure they are being properly taken care of. Unfortunately, some of these poorer communities are unable to correctly and accurately document that they qualify for the amount of aid they tend to need. The goal of this project is to take observable attributes of a given household and bucket them into different poverty levels.

The data provided includes 142 predictor variables, with a decent spread between categorical, numeric, and binary values. Our response, **Target**, is a categorical variable with 4 levels, and each row represents an observed individual. Below is a list of variables with some omitted or modified for clarity:

```{r, include=T}
#make a nice GT table with a smaller list of vars
Variable = c('v2a1','hacdor','rooms','hacapo','v14a','refrig','v18q1','r4t1',
             'r4t2','escolari','rez_esc','hhsize','pared','piso','techo',
             'cielorazo','abastagua','elec','sanitario','energcocinar',
             'elimbasu','epared','etecho','eviv','dis','gender','estadocivil',
             'parentesco','hogar_nin','hogar_adul','hogar_mayor','dependency',
             'edjife','edjifa','meaneduc','instlevel','bedrooms','tipovivi',
             'computer','television','lugar','area','age','Target')


Type = c('Numeric','Numeric','Numeric','Numeric','Binary','Binary','Numeric',
         'Numeric','Numeric','Numeric','Numeric','Numeric','Categorical',
         'Categorical','Categorical','Binary','Categorical','Categorical',
         'Categorical','Categorical','Categorical','Numeric','Numeric',
         'Numeric','Binary','Binary','Categorical','Categorical','Numeric',
         'Numeric','Numeric','Numeric','Numeric','Numeric','Numeric',
         'Categorical','Numeric','Categorical','Binary','Binary','Categorical',
         'Binary','Numeric','Categorical')


Description = c('Monthly rent payment','Overcrowding by bedrooms',
                'Number of rooms in house','Overcrowding by all rooms',
                'Has bathroom in household','Has refrigerator in household',
                'Number of tablets household owns',
                'Persons younger than 12 years','Persons older than 12 years',
                'Years of schooling','Years behind in school','Household size',
                'Wall material','Floor material','Roof material',
                'Presence of ceiling in home','Home water source',
                'Home electricity source','Home plumbing type',
                'Home kitchen type','Home waste disposal type','Wall quality',
                'Roof quality','Floor quality','Individual is disabled',
                'Individual gender','Individual civil status',
                'Relation to head of household','Individuals under 19',
                'Individuals between 19 and 65','Individuals >65',
                'Ratio of dependents/independents',
                'Education of head of household (male)',
                'Education of head of household (female)',
                'Mean years of education in household',
                'Highest form of education achieved','Number of bedrooms',
                'House status (rent, own, etc)',
                'Presence of household computer','Presence of household TV',
                'Region','Urban/Rural','Individual age',
                'Household poverty level')


as.data.frame(t(as.data.frame(rbind(Variable,Type,Description)))) %>%
  gt() %>%
  gt_theme_nytimes()
```

Furthermore, our response variable **Target** has the following categories which we will attempt to classify households into:

```{r, include=T}
Level = c(1,2,3,4)

Description = c('Extreme poverty','Moderate poverty',
                'Vulnerable','Non-vulnerable')

#table(data$Target)

Count = c(211,420,339,1849)

as.data.frame(t(as.data.frame(rbind(Level,Description,Count)))) %>%
  gt() %>%
  gt_theme_nytimes()
```

As shown by the counts, the data is rather imbalanced within the levels of vulnerability will be accounted for in future processes.

# Data Cleaning and Exploration

There are several variables, such as SQBescolari, SQBage, SQBhogar_total, SQBedjefe, SQBhogar_nin, SQBovercrowding, SQBdependency, SQBmeaned, agesq, that we deemed irrelevant to our analysis. These variables are squares of other existing variables so they were removed from the dataset to avoid colinearity with their non-square counterparts. Additional data cleaning steps address missing values, standardize data formats, and compute new variables to ensure the dataset is ready for analysis. Missing values are filled with logical defaults or calculated averages. One example of this is replacing v2a1 (rent payment) and v18q1 (tablets owned) with zero, or using the mean education level for specific age groups to impute meaneduc. Categorical variables, like edjefa and edjefe, are converted into binary numeric formats. Dependency ratios are recalculated at the household level using age group distributions, and a binary indicator for school attendance is created.

Once these steps have been executed, new variables were constructed to address the ambiguity of some of the existing features. Some of these variables create household-level summaries, such as counts of individuals in school, children behind in their schooling, and disabled household members, and identifies households with non-family members. A filter is applied to the dataset to include only heads of households and removes redundant or constant features. Housing quality is quantified through composite scores for interior, exterior, and overall quality based on materials and utilities. To visualize household dependencies, a simple scatterplot was created.

```{r}
data_cleaner = function(data){
  #remove redundant variables
  data = data %>% select(-c(SQBescolari, SQBage, SQBhogar_total, SQBedjefe,
                            SQBhogar_nin, SQBovercrowding, SQBdependency, 
                            SQBmeaned,agesq))
  
  ### Fill NAs ###
  #colSums(is.na(data))
  
  #6405 v2a1: rent payment
  house_types = cbind(data$v2a1, data$tipovivi1, data$tipovivi2,
                      data$tipovivi3, data$tipovivi4, data$tipovivi5)
  
  colSums(is.na(as.data.frame(house_types) %>% filter(data$tipovivi5 == 1))) 
  #5600 tipovivi1: owned
  #153 tipovivi4: precarious
  #751 tipoivi5: assigned
  
  #assign 0 to NA in v2a1
  data$v2a1[is.na(data$v2a1)] = 0
  
  
  #v18q1 tablets owned:
  tabs = cbind(data$v18q, data$v18q1)
  # NA if zero, so replace with 0.
  data$v18q1[is.na(data$v18q1)] = 0
  
  
  #rez_esc: years behind in school
  school = as.data.frame(cbind(data$rez_esc, data$age))
  school_not_na = school %>% filter(!is.na(school$V1))
  #applies only to those in school (7-17)
  #fill with 0
  #in school binary
  data$in_school = as.numeric(!is.na(data$rez_esc))
  data$rez_esc[is.na(data$rez_esc)] = 0
  
  
  #meaneduc: avg edu for adults
  age18 = data %>% filter(age == 19 | age == 18)
  mean(na.omit(age18$meaneduc)) #13.66
  mean(na.omit(data$meaneduc)) #9.23
  #since small portion (5 obs), fill with mean for age (13.66)
  data$meaneduc[is.na(data$meaneduc)] = 13.66
  
  
  ### Standardize types ###
  #sapply(data, class) 
  
  #edjefe/edjefa
  #yes=1, no=0
  data$edjefa[data$edjefa == 'no'] = 0
  data$edjefa[data$edjefa == 'yes'] = 1
  data$edjefa = as.numeric(data$edjefa)
  
  data$edjefe[data$edjefe == 'no'] = 0
  data$edjefe[data$edjefe == 'yes'] = 1
  data$edjefe = as.numeric(data$edjefe)
  
  
  # #dependancy: (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)         
  table(data$dependency)
  
  #calculate for missing vals (0 if none)
  dependency_calc = data %>%
    group_by(idhogar) %>%
    summarise(count_in_range = sum(age >= 19 & age <= 64),
              count_out_range = sum(!(age >= 19 & age <= 64)),
              ratio = ifelse(count_out_range == 0, 0, count_in_range / count_out_range))
  
  result = inner_join(data, dependency_calc, by = "idhogar")
  result = result %>% select(-c(count_in_range, count_out_range,dependency))
  result$dependency = result$ratio
  data = result %>% select(-c(ratio))
  
  
  
  ##### New Variables #####
  
  #new var for number of people in school by household
  school_count = data %>%
    group_by(idhogar) %>%
    summarise(school_count = sum(in_school == 1))
  
  data = inner_join(data, school_count, by = "idhogar")
  
  
  #count of children behind in school
  children_behind = data %>%
    group_by(idhogar) %>%
    summarise(children_behind = sum(rez_esc != 0))
  
  data = inner_join(data, children_behind, by = "idhogar")
  
  
  #count of disabled people in house
  disabled_count = data %>%
    group_by(idhogar) %>%
    summarise(dis_count = sum(dis == 1))
  
  data = inner_join(data, disabled_count, by = "idhogar")
  
  
  #has non-family in household binary
  non_fam = data %>%
    group_by(idhogar) %>%
    summarise(non_family = as.numeric(any(parentesco12 != 0)))
  
  data = inner_join(data, non_fam, by = "idhogar")
  
  
  #split ids
  numeric_data = data %>% select(-c(Id,idhogar,Target))
  
  #check correlations (spearman for nonlinear)
  # corrs = cor(numeric_data, method = 'spearman') %>%
  #           as.data.frame() %>%
  #           mutate(var1 = rownames(.)) %>%
  #           gather(var2, value, -var1) %>%
  #           arrange(desc(value)) %>%
  #           group_by(value) %>%
  #           filter(row_number()==1)
  # 
  # corrs = corrs[corrs$value >= .7 | corrs$value <= -.7,]
  
  #tamhog, tamviv, r4t3 basically same info
  # male/female, area1/area2, and abast... should be binary
  
  #remove more redundant data
  data = data %>% select(-c(female, area2, abastaguafuera, tamhog, tamviv, v18q,in_school))
  
  
  #which vars are not the same within households
  # independent_vars = data %>%
  #   group_by(idhogar) %>%
  #   summarize(across(everything(), ~ n_distinct(.) > 1)) %>%
  #   select(-idhogar) %>%
  #   summarize(across(everything(), any)) %>%
  #   pivot_longer(cols = everything(), names_to = "Column", values_to = "NotConstant") %>%
  #   filter(NotConstant) %>%
  #   pull(Column)
  # 
  # print(independent_vars)
  
  
  ##### Head of Household Data ####
  
  data_hh = data %>%
    filter(parentesco1 == 1) %>%
    select(-c(r4h1,r4h2,r4h3,r4m1,r4m2,r4m3,r4t2,r4t3,
              mobilephone,edjefe,edjefa,dis, #redundant
              parentesco1,parentesco2,parentesco3,parentesco4,parentesco5,
              parentesco6,parentesco7,parentesco8,parentesco9,parentesco10,
              parentesco11,parentesco12, #all are in parentesco1, so useless
              elimbasu5, estadocivil1, #all zero
              Id, idhogar
              ))
  
  #which(colSums(data_hh) == 0) #remove 0s
  
  ### House quality variable ###
  
  #pisonotiene: no floor
  #pareddes: waste walls
  #cielorazo=0: no ceiling
  #noelec
  #sanitario1: no toilet
  #energcocinar1: no kitchen
  #refrig=0: no refridgerator
  
  #epared1-3: wall quality
  #etecho1-3:roof quality
  #eviv: floor quality
  
  house_vars = data_hh %>%
    select(c(pisonotiene,pareddes,cielorazo,noelec,sanitario1,refrig,
             energcocinar1,epared1,epared2,epared3,etecho1,etecho2,
             etecho3,eviv1,eviv2,eviv3))
  
  #flip binary to make same as others
  house_vars$refrig = as.numeric(house_vars$refrig == 0)
  house_vars$cielorazo = as.numeric(house_vars$cielorazo == 0)
  
  #exterior vars
  house_vars$wall_qual = ifelse(house_vars$epared1 == 1, 0,
              ifelse(house_vars$epared2 == 1, .5,
              ifelse(house_vars$epared3 == 1, 1,999)))
  
  house_vars$roof_qual = ifelse(house_vars$etecho1 == 1, 0,
              ifelse(house_vars$etecho2 == 1, .5,
              ifelse(house_vars$etecho3 == 1, 1,999)))
  
  house_vars$floor_qual = ifelse(house_vars$eviv1 == 1, 0,
              ifelse(house_vars$eviv2 == 1, .5,
              ifelse(house_vars$eviv3 == 1, 1,999)))
  
  house_vars$exterior_qual = house_vars %>%
    select(roof_qual,wall_qual,floor_qual) %>%
    rowMeans()
  
  #interior vars
  house_vars$interior_qual = house_vars %>%
    select(pisonotiene,pareddes,cielorazo,noelec,sanitario1,energcocinar1,refrig) %>%
    rowMeans()
  
  house_vars$interior_qual = 1-house_vars$interior_qual
  
  
  house_vars = house_vars %>% select(-c(epared1,epared2,epared3,
                                        etecho1,etecho2,etecho3,
                                        eviv1,eviv2,eviv3))
  
  house_vars$house_qual = house_vars %>%
    select(interior_qual, exterior_qual) %>%
    rowMeans()
  
  #put back in full dataset
  data_hh$interior_qual = house_vars$interior_qual
  data_hh$exterior_qual = house_vars$exterior_qual
  data_hh$house_qual = house_vars$house_qual
  
  return(data_hh)
}

data = data_cleaner(read.csv('poverty.csv'))
test_data = data_cleaner(read.csv('poverty-test-blinded.csv')) #works on test data.
```

```{r, include=T,fig.dim = c(8, 4)}
ggplot(data, aes(x = dependency, y = house_qual)) +
  geom_point(alpha = 0.6, color = "blue") + 
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Dependency vs House Quality",
    x = "Dependency Ratio",
    y = "House Quality Score"
  ) +
  theme_minimal()
```

As we can see from this plot, as dependency ratio increases, the house quality seems to have a slightly larger spread which could indicate that having more dependents could have an impact on the quality of a household. Another argument that could be made is that people that have more dependents appear to be in a position to provide for these dependents since there seems to be an upward trend of the house quality score as the dependency ratio increases. Additionally, there could be a relationship between the education level and the house quality. To view this, another scatterplot was made.

```{r,include=T,fig.dim = c(8, 4)}
ggplot(aes(x = house_qual, y = meaneduc, color = dependency), data = data) +
  geom_point() +
  labs(x = "House Quality", y = "Average Education Level", title = "House Quality vs Average Education Level", color = "Dependency Ratio") +
  theme_minimal()
```

As we can see in this plot, the house quality appears to have a positive relationship with average education level. There is also a smaller dependency ratio as both house quality and education level rise.

\newpage

# The Statistical Model

```{r}
#split train/test
set.seed(543)
train_ind = sample.int(dim(data)[1], dim(data)[1] * .7)
data_tr = data[train_ind,] #70% Training
data_te = data[-train_ind,] #30% Testing

#Undersampling 4's in training for model construction
tr_4<-which(data_tr$Target==4)
tr_3<-which(data_tr$Target==3)
tr_2<-which(data_tr$Target==2)
tr_1<-which(data_tr$Target==1)

set.seed(1)
keeps4 <- sample.int(length(tr_4), 150)
set.seed(1)
keeps3 <- sample.int(length(tr_3), 150)
set.seed(1)
keeps2 <- sample.int(length(tr_2), 150)
set.seed(1)
keeps1 <- sample.int(length(tr_1), 150)

undr<-c(tr_4[keeps4],tr_3[keeps3],tr_2[keeps2],tr_1[keeps1])

data_tr_bal <-data_tr[undr,]

model.test <- function(tr_model,test_data){
  probs = predict(tr_model, test_data, type = "probs")
  preds = predict(tr_model, test_data, type = "class")

  print(confusionMatrix(as.factor(preds), as.factor(test_data$Target))) #already decent
  print(auc(multiclass.roc(as.numeric(test_data$Target), as.numeric(preds))))
}
```


## Base Model

```{r}
#base model
mod0 = multinom(Target~., data=data_tr)
probs = predict(mod0, data_te, type = "probs")
preds = predict(mod0, data_te, type = "class")

model.test(mod0,data_te)
```

Our first step is to get a baseline model. Since our response is categorical with 4 levels, we will be using a multinomial logistic regression model. We separated  our data with a 70% train/test split and created a model using all variables created and retained in the data cleaning process. The performance of this model is shown below:

| **Base Model**  | 1    | 2    | 3    | 4    |
|-------------|------|------|------|------|
| Sensitivity | 0.22 | 0.31 | 0.05 | 0.91 |
| Specificity | 0.96 | 0.90 | 0.97 | 0.46 |

The initial model correctly classifies true non-vulnerable households quite well as shown by the high sensitivity in class 4. However because of the low specificity in class 4 there is potential that the model is overclassifying households into the non-vulnerable category. In the other classes the model correctly identifies true negatives very often as shown by the high specificities in classes 1, 2, and 3. The low sensitivity values in classes 1, 2, and 3 as well as the low specificity value in class 4 suggests that the model is overclassifying households as non-vulnerable to poverty.

```{r}
# #Takes a long time to run so after running it we just manually declare the models
# backward <- step(multinom(Target~., data=data_tr),  direction="backward",
#                  trace=0, steps = 20)

#Backward model
backward <- multinom(Target~.-rooms- v14a- rez_esc- techoentrepiso- techootro- 
                       abastaguadentro- abastaguano- public- planpri- coopele- 
                       male- instlevel6- instlevel7- instlevel8- instlevel9- 
                       bedrooms- computer- television- school_count- non_family,
                     data=data_tr)

anova(backward,mod0)[2,7]

model.test(backward,data_te)
```

```{r}
# #Takes a long time to run so after running it we just manually declare the models
# forward = step(multinom(Target~1, data=data_tr), 
#                scope=list(lower=multinom(Target~1, data=data_tr), 
#                           upper=multinom(Target~., data=data_tr)), 
#                direction="forward", trace=0)
# step = step(multinom(Target~1, data=data_tr), 
#             scope=list(lower=multinom(Target~1, data=data_tr), 
#                        upper=multinom(Target~., data=data_tr)), 
#             direction="both", trace=0)

#Forward/Stepwise Model
forward <- multinom(Target~meaneduc + hogar_nin + qmobilephone + house_qual + 
                      v2a1 + age + v18q1 + estadocivil5 + instlevel3 + area1 + 
                      paredblolad + epared1 + sanitario3 + estadocivil4 + 
                      techoentrepiso + hogar_adul + energcocinar2 + etecho1 + 
                      dis_count + children_behind + escolari + estadocivil2, 
                    data=data_tr)

anova(forward,mod0)[2,7]

model.test(forward,data_te)
```

To improve our model, we first attempted forward, backward, and step-wise model selection to see if simply removing some of the predictors would improve our model. While each of these techniques performed similarly to the full model they also had the same issues of low sensitivity as the full model. 

| **Backward Model**  | 1    | 2    | 3    | 4    |
|-------------|------|------|------|------|
| Sensitivity | 0.22 | 0.33 | 0.06 | 0.91 |
| Specificity | 0.97 | 0.91 | 0.97 | 0.44 |

| **Forward/Step-wise Model**  | 1    | 2    | 3    | 4    |
|-------------|------|------|------|------|
| Sensitivity | 0.17 | 0.36 | 0.00 | 0.94 |
| Specificity | 0.97 | 0.90 | 0.99 | 0.40 |

```{r,eval=F}
library(glmnet)
#Convert training data to matrix format, required for the package
xx <- model.matrix(Target~., data_tr)
yy <- data_tr$Target #packages requires this to be numeric

#Fit the lasso logistic regression
#alpha=1 gives lasso (alpha=0 gives ridge)
#Can change the model measurement. Using AUC here:

thresh = seq(from = 0, to = 1, by = 0.05)
for(t in thresh){
  lasso.out <- cv.glmnet(xx, yy, family="multinomial", alpha=t, type.measure="class")
  coef(lasso.out, s=lasso.out$lambda.min)
  
  probs = predict(lasso.out, model.matrix(Target~., data_te),type='response')
  preds = predict(lasso.out, model.matrix(Target~., data_te),type='class')
  #table(data_te$Target)
  print(t)
  print(table(preds))
}

#all elastic net are not good.
```

Next, elastic net with crossfold validation (10 folds) was employed. We initially attempted ridge regression, but noticed that the model was only predicting cases from levels 2 and 4; the two largest groups within the data. So, next we tried LASSO regression, and had nearly identical results. Finally, in order to rule out elastic net as a viable strategy for our data, we tested every $\alpha$ value between 0 and 1 in intervals of 0.05. Out of all 20 tests, $\alpha=0.3$ was able to make predictions on levels 1, 2, and 4, $\alpha=0.7$ was able to make predictions on all 4 classes, and all others were only able to predict on 2 and 4. However, neither $\alpha=0.3$ nor $\alpha=0.7$ were able to make accurate predictions, so none of the elastic net models will be used.

```{r}
#Balanced model
balmod = multinom(Target~., data=data_tr_bal)
model.test(balmod,data_te)
```

```{r}
# #Takes a long time to run so after running it we just manually declare the models
# balbackward <- step(multinom(Target~., data=data_tr_bal),  direction="backward",
#                  trace=0)

balbackward <- multinom(Target~v2a1 + hacapo + refrig + v18q1 + hhsize + 
                          paredblolad + paredzocalo + paredpreb + pareddes + 
                          paredmad + paredzinc + paredfibras + paredother + 
                          pisomoscer + pisocemento + pisoother + pisonatur + 
                          pisonotiene + pisomadera + techozinc + 
                          techoentrepiso + techocane + techootro + cielorazo + 
                          noelec + sanitario1 + sanitario2 + sanitario3 + 
                          sanitario5 + sanitario6 + energcocinar1 + 
                          energcocinar2 + energcocinar3 + energcocinar4 + 
                          elimbasu1 + elimbasu2 + elimbasu3 + elimbasu4 + 
                          elimbasu6 + epared1 + epared2 + epared3 + etecho1 + 
                          etecho2 + etecho3 + eviv1 + eviv2 + eviv3 + 
                          estadocivil2 + estadocivil3 + estadocivil4 + 
                          estadocivil5 + estadocivil6 + estadocivil7 + 
                          hogar_nin + hogar_adul + hogar_mayor + hogar_total + 
                          meaneduc + instlevel1 + instlevel2 + instlevel3 + 
                          instlevel4 + instlevel5 + instlevel6 + instlevel7 + 
                          instlevel8 + instlevel9 + bedrooms + overcrowding + 
                          tipovivi1 + tipovivi2 + tipovivi3 + tipovivi4 + 
                          tipovivi5 + qmobilephone + lugar1 + lugar2 + lugar3 + 
                          lugar4 + lugar5 + lugar6 + age + dependency + 
                          dis_count + interior_qual + exterior_qual + 
                          house_qual, data=data_tr_bal)

model.test(balbackward,data_te)

anova(balbackward,balmod)
```

```{r}
# #Takes a long time to run so after running it we just manually declare the models
# balforward = step(multinom(Target~1, data=data_tr_bal),
#             scope=list(lower=multinom(Target~1, data=data_tr_bal),
#                        upper=multinom(Target~., data=data_tr_bal)),
#             direction="forward", trace=0)
balforward <- multinom(Target~meaneduc + hogar_nin + house_qual + dis_count + 
                         v18q1 + qmobilephone + age +instlevel3 + dependency + 
                         v2a1 + energcocinar2 + estadocivil5 + estadocivil7 + 
                         overcrowding + hacdor + hhsize + etecho3 + sanitario5 + 
                         abastaguano + pisonotiene, data = data_tr_bal)
model.test(balforward,data_te)

anova(balforward,balmod)
```

```{r}
# #Takes a long time to run so after running it we just manually declare the models
# balstep = step(multinom(Target~1, data=data_tr_bal),
#             scope=list(lower=multinom(Target~1, data=data_tr_bal),
#                        upper=multinom(Target~., data=data_tr_bal)),
#             direction="both", trace=0)

balstep <- multinom(formula = Target ~ meaneduc + hogar_nin + dis_count + 
                      v18q1 + age + instlevel3 + dependency + v2a1 + 
                      energcocinar2 + estadocivil5 + estadocivil7 + 
                      overcrowding + hacdor + hhsize + etecho3 + energcocinar3, 
                    data = data_tr_bal)

model.test(balstep,data_te)

anova(balstep,balmod)
```

We hypothesized that, since the predictors appeared to not be a limiting factor, the class imbalance must be the reason for poor predictions. To address this issue we employed two difference strategies. The first being randomized under-sampling of the training data. This strategy was performed by randomly selecting 150 values from each of the 4 classes and training our model on only these values. All previously mentioned procedures were conducted on the balanced model as well. The balanced model and it's various derivatives resulted in better balance of our sensitivity values but they were still relatively low as shown in the balanced full model below:

| **Balanced Model**  | 1    | 2    | 3    | 4    |
|-------------|------|------|------|------|
| Sensitivity | 0.48 | 0.31 | 0.30 | 0.68 |
| Specificity | 0.85 | 0.85 | 0.83 | 0.83 |

```{r}
#test various class weights
#Props: 8%, 16%, 12%, 64%

test_weight = function(probs,class_weights){
  weighted_probs = sweep(probs, 2, class_weights, `*`)
  weighted_probs = sweep(weighted_probs, 1, rowSums(weighted_probs), `/`)
  adjusted_preds = colnames(weighted_probs)[apply(weighted_probs, 1, which.max)]
  print(confusionMatrix(as.factor(adjusted_preds), as.factor(data_te$Target)))
  print(auc(multiclass.roc(as.numeric(data_te$Target), as.numeric(adjusted_preds))))
}

inv_prop = c(Class1 = 1/.08, Class2 = 1/.16, Class3 = 1/.12, Class4 = 1/.64)
test_weight(probs,inv_prop)

inv_sqrt = c(Class1 = 1/sqrt(.08), Class2 = 1/sqrt(.16), Class3 = 1/sqrt(.12), Class4 = 1/sqrt(.64))
test_weight(probs,inv_sqrt)
```

The second strategy was testing a few different weights on each of the class probability predictions. The weights, along with the performance of their corresponding models, are shown below:

| Weight                         | $\kappa$ | AUC  |
|--------------------------------|----------|------|
| None                           | 0.26     | 0.65 |
| $\frac{1}{\text{prop}}$        | 0.27     | .070 |
| $\frac{1}{\sqrt{\text{prop}}}$ | 0.31     | 0.68 |

As shown, both of these models have a larger $\kappa$ value and ROC-AUC scores which suggest they perform better then the unweighted model. The trade off, however, is that neither of these new models are nearly as accurate at predicting class 4 as the unweighted version as shown below.

| **Inverse Proportion Model**  | 1    | 2    | 3    | 4    |
|-------------|------|------|------|------|
| Sensitivity | 0.50 | 0.30 | 0.32 | 0.66 |
| Specificity | 0.88 | 0.87 | 0.82 | 0.83 |


| **Inverse Square Root Proportion Model**  | 1    | 2    | 3    | 4    |
|-------------|------|------|------|------|
| Sensitivity | 0.37 | 0.35 | 0.16 | 0.83 |
| Specificity | 0.93 | 0.88 | 0.92 | 0.65 |

\newpage

## Multi-Model Approach

Since our weighted model did so much better in predicting classes 1-3, we will continue to use it. However, to improve on its lacking capabilities in predicting class 4, we will introduce a second model which *exclusively* predicts class 4.

For this model, the Target variable has been transformed to a binary classifier as to whether the case falls into class 4 or not. In this model, we want as high of an specificity as we can reasonably get, since false positives won't be classified again by model 2. Since recall (the amount of true positives divided by the total predicted positives) appears to scale linearly with threshold, we took the highest threshold with an acceptable $\kappa$ and AUC score. We chose 0.75 for it's combination of high values in all three metrics. The results are shown in the plot below:

```{r}
##### Binary class 4 predictor #####
#get true/false if in group 4
data_tr_4 = data_tr
data_tr_4$Target = data_tr$Target == 4

data_te_4 = data_te
data_te_4$Target = data_te$Target == 4

#fit model
mod_4 = multinom(Target ~ ., data = data_tr_4)
probs_4 = predict(mod_4, data_te_4, type = "probs")

#test thresh
is = seq(from = 0, to = 1, by = 0.05)
ks = c()
aucs = c()
recs = c()
for(i in is){
  preds_4 = probs_4 > i
  
  conf_mat = confusionMatrix(as.factor(preds_4),as.factor(data_te_4$Target))
  ks = c(ks, conf_mat$overall['Kappa'])
  aucs = c(aucs, auc(roc(as.numeric(data_te_4$Target), as.numeric(preds_4))))
  recs = c(recs, conf_mat$byClass["Recall"])
}

results = data.frame(cbind(is,ks,aucs,recs))
results$ratio = results$ks/results$aucs

#use .75
preds_4 = probs_4 > .75
confusionMatrix(as.factor(preds_4), as.factor(data_te_4$Target))
```

```{r, include = T, fig.dim=c(8, 4)}
results2 = gather(results, key = "var", value = "y", ks:recs)

ggplot(results2, aes(x=is, y=y, colour=var))+
  geom_line(linewidth = 1.2)+
  geom_vline(xintercept = .75,linetype='dashed')+
  labs(x='Threshold', y='Value', title = 'Metrics for classifying non-vulnerable households by threshold')+
  scale_color_discrete(labels = c("AUC", "Kappa", "Recall"))+
  theme_minimal() +
  theme(legend.title = element_blank())
```

Now that we have a threshold selected for the binary model, all we need to do is pass the values that it predicts are not 4 to the original model. The results are shown in the following table:

```{r}
##### Combine models #####
final_preds = sapply(1:nrow(data_te), 
                     function(i) {
  # bin 4/not 4
  is_4_probs = predict(mod_4, newdata = data_te[i, ], type = "probs")
  is_4 = is_4_probs > .75
  
  if (is_4 == T) {
    return(4)
  }
  
  # predict on rest
  else {
    not_4_probs = matrix(predict(mod0, newdata = data_te[i, ], type = 'probs'),nrow = 1)
    class_weights = c(Class1=1/.08,Class2=1/.16,Class3=1/.12,Class4=1/.64)

    weighted_probs = sweep(not_4_probs, 2, class_weights, `*`)
    weighted_probs = sweep(weighted_probs, 1, rowSums(weighted_probs), `/`)
    not_4_pred = which.max(weighted_probs)
    
    return(not_4_pred)
  }
})

confusionMatrix(as.factor(final_preds), as.factor(data_te$Target))
```

| **Final Model**  | 1    | 2    | 3    | 4    |
|-------------|------|------|------|------|
| Sensitivity | 0.50 | 0.30 | 0.30 | 0.68 |
| Specificity | 0.88 | 0.87 | 0.84 | 0.80 |

While the sensitivity for observations in class 4 may have fallen by a decent margin, its specificity rose to compensate. While metrics for class 2 predictions are more or less the same, metrics for class 1 and 3 predictions have seen substantial improvements. This model shows a greater emphasis on correctly identifying those vulnerable to poverty. This contrasts against our initial model which over emphasized correctly identifying those not vulnerable to poverty over identification of other classifications. We believe the new model will suggest a better allocation of resources across all poverty vulnerability classes than the initial model would have suggested.

# Results Summary

In the context of this data and the problem we are trying to address we believe the true positive rate should be optimized. A greater true positive rate will help to correctly distribute resources to vulnerable populations as those in worse tiers of poverty may need additional supports than those who are less vulnerable. Overall we have determined the imbalance in our data makes it hard for the models to classify true positive cases. This can be seen in the extremely low sensitivity and overall classification into classes 1 and 3 which are less prevalent in the data. We tried two techniques to optimize the true positive rate including probability weights and under-sampling to balance the data. Both techniques lead to higher sensitivity values for classes 1 and 3 as we intended. Ultimately we settled on the inverse proportion probability weights and a multi-model approach to optimize non-vulnerable households first and then optimize the other three classes afterwards. This was done to ensure the model accounted for all of the data in the non-vulnerable population which would not be the case when using under-sampling techniques. Therefore, the multi-model approach resulted in a greater sensitivity rate for the three vulnerable classes while not reducing the non-vulnerable classes sensitivity too much. Overall we believe our final model minimizes the limitations of all techniques employed. The most notable benefits of our approach include the utilization of as much data as possible and class weighting to alleviate over-fitting on the majority class in our data. Because of this we believe our final model is the best of the models constructed for accurately classifying poverty vulnerabilities in a way that should enable a more equitable distribution of resources.


```{r,eval=F}
#get preds on blinded data
blind_preds = sapply(1:nrow(test_data), function(i) {
  # bin 4/not 4
  is_4_probs = predict(mod_4, newdata = test_data[i, ], type = "probs")
  is_4 = is_4_probs > .75
  
  if (is_4 == T) {
    return(4)
  }
  
  # predict on rest
  else {
    not_4_probs = matrix(predict(mod0, newdata = test_data[i, ], type = 'probs'),nrow = 1)
    class_weights = c(Class1=1/.08,Class2=1/.16,Class3=1/.12,Class4=1/.64)

    weighted_probs = sweep(not_4_probs, 2, class_weights, `*`)
    weighted_probs = sweep(weighted_probs, 1, rowSums(weighted_probs), `/`)
    not_4_pred = which.max(weighted_probs)
    
    return(not_4_pred)
  }
})

write.csv(blind_preds, 'predictions.csv')
```


